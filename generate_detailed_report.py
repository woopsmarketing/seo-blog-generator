# -*- coding: utf-8 -*-
"""
ìƒì„¸í•œ ë¸”ë¡œê·¸ ìƒì„± ë¦¬í¬íŠ¸ ìƒì„±ê¸°
LSI/ë¡±í…Œì¼ í‚¤ì›Œë“œ, ì„¹ì…˜ íŒŒì´í”„ë¼ì¸, ìƒì„± ê³¼ì • ë“±ì„ í¬í•¨í•œ ì¢…í•© JSON ë¦¬í¬íŠ¸ ìƒì„±
"""

import sys
import json
from pathlib import Path
from datetime import datetime

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

from src.generators.content.keyword_generator import KeywordGenerator
from src.generators.content.title_generator import TitleGenerator, TitleOptions
from src.generators.content.outline_generator import OutlineGenerator
from src.utils.config import load_config

class DetailedReportGenerator:
    """ìƒì„¸í•œ ë¸”ë¡œê·¸ ìƒì„± ë¦¬í¬íŠ¸ ìƒì„±ê¸°"""
    
    def __init__(self):
        self.config = load_config()
        self.keyword_generator = KeywordGenerator()
        
    def generate_detailed_report(self, keyword: str, existing_files: dict = None) -> dict:
        """í‚¤ì›Œë“œì— ëŒ€í•œ ìƒì„¸í•œ ìƒì„± ë¦¬í¬íŠ¸ ìƒì„±"""
        
        print(f"ğŸ” '{keyword}' í‚¤ì›Œë“œ ìƒì„¸ ë¶„ì„ ì‹œì‘...")
        
        # 1. í‚¤ì›Œë“œ ì „ëµ ìƒì„±
        print("1ï¸âƒ£ í‚¤ì›Œë“œ ì „ëµ ë¶„ì„ ì¤‘...")
        keyword_strategy = self.keyword_generator.generate_keyword_strategy(keyword)
        
        # 2. ì œëª© ìƒì„± (ê¸°ì¡´ íŒŒì¼ì´ ìˆë‹¤ë©´ ì¬ì‚¬ìš©)
        print("2ï¸âƒ£ ì œëª© ìƒì„± ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
        title_generator = TitleGenerator(self.config)
        title_result = title_generator.generate_title(
            keyword=keyword,
            options=TitleOptions(
                max_length=60, include_numbers=True, include_year=True, tone="professional"
            )
        )
        
        # 3. ì•„ì›ƒë¼ì¸ ìƒì„± ì •ë³´
        print("3ï¸âƒ£ ì•„ì›ƒë¼ì¸ êµ¬ì¡° ë¶„ì„ ì¤‘...")
        outline_generator = OutlineGenerator()
        outline = outline_generator.generate_outline(keyword=keyword, title=title_result.title)
        
        # 4. ê¸°ì¡´ íŒŒì¼ì—ì„œ ì •ë³´ ì¶”ì¶œ (ìˆëŠ” ê²½ìš°)
        existing_content = {}
        if existing_files:
            existing_content = self._extract_existing_content(existing_files)
        
        # 5. ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
        print("4ï¸âƒ£ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        detailed_report = self._create_detailed_report(
            keyword=keyword,
            keyword_strategy=keyword_strategy,
            title_result=title_result,
            outline=outline,
            existing_content=existing_content
        )
        
        print("âœ… ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
        return detailed_report
    
    def _extract_existing_content(self, existing_files: dict) -> dict:
        """ê¸°ì¡´ ìƒì„±ëœ íŒŒì¼ë“¤ì—ì„œ ì½˜í…ì¸  ì •ë³´ ì¶”ì¶œ"""
        content_info = {}
        
        # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë¶„ì„
        if 'markdown' in existing_files:
            md_path = Path(existing_files['markdown'])
            if md_path.exists():
                with open(md_path, 'r', encoding='utf-8') as f:
                    md_content = f.read()
                    content_info['markdown'] = {
                        'file_size': len(md_content),
                        'line_count': len(md_content.splitlines()),
                        'h2_count': md_content.count('## '),
                        'h3_count': md_content.count('### '),
                        'sections': self._extract_sections_from_markdown(md_content)
                    }
        
        # HTML íŒŒì¼ ë¶„ì„
        if 'html' in existing_files:
            html_path = Path(existing_files['html'])
            if html_path.exists():
                with open(html_path, 'r', encoding='utf-8') as f:
                    html_content = f.read()
                    content_info['html'] = {
                        'file_size': len(html_content),
                        'line_count': len(html_content.splitlines()),
                        'h2_tags': html_content.count('<h2'),
                        'h3_tags': html_content.count('<h3'),
                        'p_tags': html_content.count('<p'),
                        'css_classes': self._extract_css_classes(html_content)
                    }
        
        return content_info
    
    def _extract_sections_from_markdown(self, md_content: str) -> list:
        """ë§ˆí¬ë‹¤ìš´ì—ì„œ ì„¹ì…˜ êµ¬ì¡° ì¶”ì¶œ"""
        import re
        sections = []
        
        # H2 ì„¹ì…˜ ì¶”ì¶œ
        h2_pattern = r'^## (.+)$'
        h2_matches = re.findall(h2_pattern, md_content, re.MULTILINE)
        
        for h2_title in h2_matches:
            # í•´ë‹¹ H2 ì„¹ì…˜ì˜ H3ë“¤ ì°¾ê¸°
            h2_index = md_content.find(f'## {h2_title}')
            next_h2_index = md_content.find('## ', h2_index + 1)
            if next_h2_index == -1:
                next_h2_index = len(md_content)
            
            section_content = md_content[h2_index:next_h2_index]
            h3_pattern = r'^### (.+)$'
            h3_matches = re.findall(h3_pattern, section_content, re.MULTILINE)
            
            # ì„¹ì…˜ ê¸¸ì´ ê³„ì‚°
            section_text = re.sub(r'^#+\s.*$', '', section_content, flags=re.MULTILINE)
            section_length = len(section_text.strip())
            
            sections.append({
                'h2_title': h2_title,
                'h3_titles': h3_matches,
                'h3_count': len(h3_matches),
                'content_length': section_length,
                'estimated_read_time': max(1, section_length // 200)  # 200ì/ë¶„ ê¸°ì¤€
            })
        
        return sections
    
    def _extract_css_classes(self, html_content: str) -> dict:
        """HTMLì—ì„œ ì‚¬ìš©ëœ CSS í´ë˜ìŠ¤ ì¶”ì¶œ"""
        import re
        css_classes = {}
        
        # class ì†ì„± ì¶”ì¶œ
        class_pattern = r'class="([^"]+)"'
        matches = re.findall(class_pattern, html_content)
        
        for class_attr in matches:
            classes = class_attr.split()
            for cls in classes:
                css_classes[cls] = css_classes.get(cls, 0) + 1
        
        return css_classes
    
    def _create_detailed_report(self, keyword: str, keyword_strategy, title_result, outline, existing_content: dict) -> dict:
        """ì¢…í•© ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        # LSI í‚¤ì›Œë“œ ì •ë³´ ì¶”ì¶œ
        lsi_keywords = []
        for lsi in keyword_strategy.lsi_keywords:
            lsi_keywords.append({
                'keyword': lsi.keyword,
                'relevance_score': lsi.relevance_score,
                'context': lsi.context
            })
        
        # ë¡±í…Œì¼ í‚¤ì›Œë“œ ì •ë³´ ì¶”ì¶œ
        longtail_keywords = []
        for lt in keyword_strategy.longtail_keywords:
            longtail_keywords.append({
                'phrase': lt.phrase,
                'search_intent': lt.search_intent,
                'difficulty': lt.difficulty
            })
        
        # ì•„ì›ƒë¼ì¸ ì„¹ì…˜ ì •ë³´ ì¶”ì¶œ
        sections_info = []
        for i, section in enumerate(outline.sections, 1):
            sections_info.append({
                'section_id': str(i),
                'h2_title': section.h2,
                'h3_titles': section.h3,
                'h3_count': len(section.h3),
                'h4_map': section.h4_map,
                'expected_length': 400 + (len(section.h3) * 150)  # ì˜ˆìƒ ê¸¸ì´ ê³„ì‚°
            })
        
        # ë©”íƒ€ ì •ë³´
        meta_info = {
            'intent': outline.meta.intent,
            'estimated_length': outline.meta.estimated_length,
            'target_keyword': outline.meta.target_keyword,
            'seo_strategy': outline.meta.seo_strategy
        }
        
        # ìƒì„± íŒŒì´í”„ë¼ì¸ ì •ë³´
        generation_pipeline = {
            'steps': [
                {
                    'step_number': 1,
                    'step_name': 'keyword_analysis',
                    'description': 'LSI í‚¤ì›Œë“œ ë° ë¡±í…Œì¼ í‚¤ì›Œë“œ ë¶„ì„',
                    'output': f'LSI {len(lsi_keywords)}ê°œ, ë¡±í…Œì¼ {len(longtail_keywords)}ê°œ ìƒì„±'
                },
                {
                    'step_number': 2,
                    'step_name': 'title_generation',
                    'description': 'SEO ìµœì í™” ì œëª© ìƒì„±',
                    'output': f'ì œëª©: {title_result.title}, SEO ì ìˆ˜: {title_result.seo_score}/10'
                },
                {
                    'step_number': 3,
                    'step_name': 'outline_generation',
                    'description': 'JSON êµ¬ì¡°í™”ëœ ì•„ì›ƒë¼ì¸ ìƒì„±',
                    'output': f'{len(sections_info)}ê°œ ì„¹ì…˜, ì´ {sum(len(s["h3_titles"]) for s in sections_info)}ê°œ H3 êµ¬ì¡°'
                },
                {
                    'step_number': 4,
                    'step_name': 'content_generation',
                    'description': 'LangChain ë©”ëª¨ë¦¬ ê¸°ë°˜ ì„¹ì…˜ë³„ ì½˜í…ì¸  ìƒì„±',
                    'output': 'ìì—°ìŠ¤ëŸ¬ìš´ íë¦„ê³¼ ì¼ê´€ì„± ìˆëŠ” ì½˜í…ì¸ '
                },
                {
                    'step_number': 5,
                    'step_name': 'markdown_output',
                    'description': 'ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì¡°ë¦½ ë° ì €ì¥',
                    'output': 'êµ¬ì¡°í™”ëœ MD íŒŒì¼ ìƒì„±'
                },
                {
                    'step_number': 6,
                    'step_name': 'html_conversion',
                    'description': 'ì›Œë“œí”„ë ˆìŠ¤ REST APIìš© HTML ë³€í™˜',
                    'output': 'CSS í´ë˜ìŠ¤ê°€ ì ìš©ëœ HTML êµ¬ì¡°'
                }
            ],
            'total_steps': 6,
            'automation_level': 'ì™„ì „ ìë™í™”',
            'manual_intervention': 'None'
        }
        
        # ì¢…í•© ë¦¬í¬íŠ¸
        report = {
            # ê¸°ë³¸ ì •ë³´
            'report_info': {
                'keyword': keyword,
                'title': title_result.title,
                'generation_date': datetime.now().isoformat(),
                'report_version': '2.0'
            },
            
            # í‚¤ì›Œë“œ ì „ëµ
            'keyword_strategy': {
                'primary_keyword': keyword_strategy.primary_keyword,
                'target_frequency': keyword_strategy.target_frequency,
                'semantic_variations': keyword_strategy.semantic_variations,
                'lsi_keywords': lsi_keywords,
                'longtail_keywords': longtail_keywords,
                'keyword_analysis': {
                    'lsi_count': len(lsi_keywords),
                    'longtail_count': len(longtail_keywords),
                    'avg_relevance_score': sum(lsi.relevance_score for lsi in keyword_strategy.lsi_keywords) / len(lsi_keywords) if lsi_keywords else 0,
                    'difficulty_distribution': self._analyze_difficulty_distribution(longtail_keywords)
                }
            },
            
            # ì œëª© ìƒì„± ì •ë³´
            'title_generation': {
                'final_title': title_result.title,
                'seo_score': title_result.seo_score,
                'keyword_density': title_result.keyword_density,
                'reasoning': title_result.reasoning,
                'alternative_titles': title_result.alternatives,
                'title_analysis': {
                    'character_count': len(title_result.title),
                    'word_count': len(title_result.title.split()),
                    'keyword_included': keyword in title_result.title,
                    'numbers_included': any(char.isdigit() for char in title_result.title)
                }
            },
            
            # ì•„ì›ƒë¼ì¸ êµ¬ì¡°
            'outline_structure': {
                'meta_info': meta_info,
                'sections': sections_info,
                'structure_analysis': {
                    'total_sections': len(sections_info),
                    'total_h3_count': sum(len(s['h3_titles']) for s in sections_info),
                    'avg_h3_per_section': sum(len(s['h3_titles']) for s in sections_info) / len(sections_info) if sections_info else 0,
                    'estimated_total_length': sum(s['expected_length'] for s in sections_info),
                    'section_types': self._categorize_sections(sections_info)
                }
            },
            
            # ìƒì„± íŒŒì´í”„ë¼ì¸
            'generation_pipeline': generation_pipeline,
            
            # ê¸°ìˆ  ì •ë³´
            'technical_info': {
                'llm_provider': self.config['llm']['default_provider'],
                'llm_model': self.config['llm']['openai_model'],
                'temperature': self.config['llm']['temperature'],
                'langchain_features': [
                    'ConversationSummaryMemory',
                    'DocumentMemoryManager', 
                    'FactTracker',
                    'StyleAnalyzer'
                ],
                'output_formats': ['markdown', 'html', 'json'],
                'css_framework': 'WordPress compatible classes'
            },
            
            # ê¸°ì¡´ ì½˜í…ì¸  ì •ë³´ (ìˆëŠ” ê²½ìš°)
            'generated_content': existing_content if existing_content else {},
            
            # SEO ë¶„ì„
            'seo_analysis': {
                'target_keyword_frequency': keyword_strategy.target_frequency,
                'keyword_density_target': '1.5-2.0%',
                'heading_structure': 'H1 > H2 > H3',
                'meta_optimization': 'WordPress plugin ìë™ ìƒì„±',
                'content_length': outline.meta.estimated_length,
                'readability_target': 'General audience',
                'search_intent': outline.meta.intent
            },
            
            # í’ˆì§ˆ ë©”íŠ¸ë¦­
            'quality_metrics': {
                'seo_score': title_result.seo_score,
                'structure_completeness': 100,  # ëª¨ë“  ì„¹ì…˜ ìƒì„±ë¨
                'keyword_optimization': 85,     # LSI/ë¡±í…Œì¼ í†µí•©
                'content_coherence': 90,        # LangChain ë©”ëª¨ë¦¬ ì‚¬ìš©
                'technical_readiness': 95,      # HTML ë³€í™˜ ì™„ë£Œ
                'overall_score': round((title_result.seo_score * 10 + 85 + 90 + 95) / 4, 1)
            }
        }
        
        return report
    
    def _analyze_difficulty_distribution(self, longtail_keywords: list) -> dict:
        """ë¡±í…Œì¼ í‚¤ì›Œë“œ ë‚œì´ë„ ë¶„í¬ ë¶„ì„"""
        if not longtail_keywords:
            return {}
        
        difficulty_counts = {}
        for keyword in longtail_keywords:
            difficulty = keyword['difficulty']
            difficulty_counts[difficulty] = difficulty_counts.get(difficulty, 0) + 1
        
        return difficulty_counts
    
    def _categorize_sections(self, sections_info: list) -> dict:
        """ì„¹ì…˜ ìœ í˜•ë³„ ë¶„ë¥˜"""
        section_types = {
            'introduction': 0,
            'guide': 0,
            'methods': 0,
            'practical': 0,
            'faq': 0,
            'conclusion': 0
        }
        
        for section in sections_info:
            title = section['h2_title'].lower()
            if 'ê°œìš”' in title or 'ì†Œê°œ' in title:
                section_types['introduction'] += 1
            elif 'ì‹œì‘' in title or 'ê°€ì´ë“œ' in title:
                section_types['guide'] += 1
            elif 'ë°©ë²•' in title or 'ì „ëµ' in title:
                section_types['methods'] += 1
            elif 'ë…¸í•˜ìš°' in title or 'ì‹¤ë¬´' in title:
                section_types['practical'] += 1
            elif 'faq' in title or 'ì§ˆë¬¸' in title:
                section_types['faq'] += 1
            elif 'ë§ˆë¬´ë¦¬' in title or 'ê²°ë¡ ' in title:
                section_types['conclusion'] += 1
        
        return section_types

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # í•œê¸€ ì¶œë ¥ ì¸ì½”ë”© ì„¤ì •
    if sys.platform.startswith('win'):
        import codecs
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.detach())
    
    print("ğŸ“Š ìƒì„¸í•œ ë¸”ë¡œê·¸ ìƒì„± ë¦¬í¬íŠ¸ ìƒì„±ê¸°")
    print("=" * 50)
    
    # ë¦¬í¬íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™”
    generator = DetailedReportGenerator()
    
    # í´ë¡œë“œì½”ë“œ í‚¤ì›Œë“œë¡œ ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„±
    keyword = "í´ë¡œë“œì½”ë“œ"
    existing_files = {
        'markdown': 'data/blog_í´ë¡œë“œì½”ë“œ_20250826_212133.md',
        'html': 'data/blog_í´ë¡œë“œì½”ë“œ_20250826_212133_final.html'
    }
    
    # ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„±
    detailed_report = generator.generate_detailed_report(keyword, existing_files)
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_filename = f"detailed_report_{keyword}_{timestamp}.json"
    report_path = Path("data") / report_filename
    
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(detailed_report, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {report_path}")
    
    # ë¦¬í¬íŠ¸ ìš”ì•½ ì¶œë ¥
    print("\nğŸ“‹ ë¦¬í¬íŠ¸ ìš”ì•½")
    print("-" * 30)
    print(f"ğŸ¯ í‚¤ì›Œë“œ: {detailed_report['report_info']['keyword']}")
    print(f"ğŸ“ ì œëª©: {detailed_report['report_info']['title']}")
    print(f"â­ SEO ì ìˆ˜: {detailed_report['title_generation']['seo_score']}/10")
    print(f"ğŸ”— LSI í‚¤ì›Œë“œ: {detailed_report['keyword_strategy']['keyword_analysis']['lsi_count']}ê°œ")
    print(f"ğŸ¯ ë¡±í…Œì¼ í‚¤ì›Œë“œ: {detailed_report['keyword_strategy']['keyword_analysis']['longtail_count']}ê°œ")
    print(f"ğŸ“Š ì´ ì„¹ì…˜: {detailed_report['outline_structure']['structure_analysis']['total_sections']}ê°œ")
    print(f"ğŸ“ ì˜ˆìƒ ê¸¸ì´: {detailed_report['outline_structure']['structure_analysis']['estimated_total_length']:,}ì")
    print(f"ğŸ† ì „ì²´ í’ˆì§ˆ ì ìˆ˜: {detailed_report['quality_metrics']['overall_score']}/100")
    
    print(f"\nğŸ’¾ ìƒì„¸ ì •ë³´ëŠ” {report_filename} íŒŒì¼ì—ì„œ í™•ì¸í•˜ì„¸ìš”!")

if __name__ == "__main__":
    main()