# config.example.py
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì˜ˆì œ íŒŒì¼
# ì´ íŒŒì¼ì„ ì°¸ê³ í•˜ì—¬ .env íŒŒì¼ì„ ìƒì„±í•˜ê±°ë‚˜ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”

"""
í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ê°€ì´ë“œ:

1. .env íŒŒì¼ ìƒì„±:
   - í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— .env íŒŒì¼ì„ ë§Œë“œì„¸ìš”
   - ì•„ëž˜ ë³€ìˆ˜ë“¤ì„ ë³µì‚¬í•˜ì—¬ ì‹¤ì œ ê°’ìœ¼ë¡œ ë°”ê¾¸ì„¸ìš”

2. í•„ìˆ˜ ì„¤ì •:
   - OPENAI_API_KEY ë˜ëŠ” ANTHROPIC_API_KEY ì¤‘ í•˜ë‚˜ëŠ” ë°˜ë“œì‹œ ì„¤ì •
   - DEFAULT_LLM_PROVIDERë¡œ ì‚¬ìš©í•  í”„ë¡œë°”ì´ë” ì§€ì •

3. .env íŒŒì¼ ì˜ˆì‹œ:
"""

ENV_TEMPLATE = """
# LLM API í‚¤ ì„¤ì • (í•„ìˆ˜)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# ê¸°ë³¸ LLM í”„ë¡œë°”ì´ë” (openai ë˜ëŠ” anthropic)
DEFAULT_LLM_PROVIDER=openai

# ëª¨ë¸ ì„¤ì • (GPT-5 ì‹œë¦¬ì¦ˆ)
OPENAI_MODEL=gpt-5-nano
ANTHROPIC_MODEL=claude-3-sonnet-20240229
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000

# WordPress ì„¤ì • (ì„ íƒì‚¬í•­)
WP_URL=https://yourblog.com
WP_USERNAME=your_wp_username
WP_PASSWORD=your_wp_app_password

# ë¡œê¹… ì„¤ì •
LOG_LEVEL=INFO
LOG_FILE=blog_generation.log

# ì½˜í…ì¸  ì„¤ì •
MIN_SECTION_LENGTH=300
MAX_SECTION_LENGTH=500
TARGET_TOTAL_LENGTH=3000
"""

# GPT-5 ì‹œë¦¬ì¦ˆ ëª¨ë¸ ì •ë³´
GPT5_MODELS = {
    "gpt-5-nano": {
        "description": "ê°€ìž¥ ë¹ ë¥´ê³  ê²½ì œì ì¸ GPT-5 ëª¨ë¸",
        "context_window": 400000,
        "input_cost": "$0.05/1M tokens",
        "output_cost": "$0.40/1M tokens",
        "best_for": ["ì¼ìƒì ì¸ ì§ˆë¬¸", "ë¹ ë¥¸ ì‘ë‹µ", "ë¹„ìš© ìµœì í™”"],
        "temperature_support": False,  # GPT-5 ì‹œë¦¬ì¦ˆëŠ” temperature ê³ ì •
        "special_features": ["fastest_response", "ultra_low_latency", "cost_effective"],
    },
    "gpt-5-mini": {
        "description": "ê· í˜•ìž¡ížŒ ì„±ëŠ¥ê³¼ ë¹„ìš©ì˜ GPT-5 ëª¨ë¸",
        "context_window": 400000,
        "input_cost": "$0.25/1M tokens",
        "output_cost": "$2.00/1M tokens",
        "best_for": ["ì •ì˜ëœ ìž‘ì—…", "ê· í˜•ìž¡ížŒ í’ˆì§ˆ", "ì¼ë°˜ì ì¸ ìš©ë„"],
        "temperature_support": False,
        "special_features": ["balanced_performance", "cost_effective", "defined_tasks"],
    },
    "gpt-5": {
        "description": "ìµœê³  ì„±ëŠ¥ì˜ í”Œëž˜ê·¸ì‹­ GPT-5 ëª¨ë¸",
        "context_window": 400000,
        "input_cost": "$1.25/1M tokens",
        "output_cost": "$10.00/1M tokens",
        "best_for": ["ë³µìž¡í•œ ì¶”ë¡ ", "ì½”ë”©", "ê³ í’ˆì§ˆ ì½˜í…ì¸ "],
        "temperature_support": False,
        "special_features": [
            "best_performance",
            "complex_reasoning",
            "coding_excellence",
        ],
    },
}


def print_config_guide():
    """ì„¤ì • ê°€ì´ë“œ ì¶œë ¥"""
    print("=" * 60)
    print("SEO ë¸”ë¡œê·¸ ìžë™ ìƒì„± ì‹œìŠ¤í…œ - í™˜ê²½ ì„¤ì • ê°€ì´ë“œ")
    print("=" * 60)

    print("\nðŸ“‹ í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜:")
    print(ENV_TEMPLATE)

    print("\nðŸš€ GPT-5 ì‹œë¦¬ì¦ˆ ëª¨ë¸ ì •ë³´:")
    for model_name, info in GPT5_MODELS.items():
        print(f"\n  ðŸ”¹ {model_name}")
        print(f"     ì„¤ëª…: {info['description']}")
        print(f"     ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°: {info['context_window']:,} í† í°")
        print(f"     ë¹„ìš©: {info['input_cost']} (ìž…ë ¥) / {info['output_cost']} (ì¶œë ¥)")
        print(f"     ìµœì  ìš©ë„: {', '.join(info['best_for'])}")
        print(
            f"     Temperature ì„¤ì •: {'ì§€ì› ì•ˆí•¨ (ê³ ì •ê°’)' if not info['temperature_support'] else 'ì§€ì›'}"
        )

    print("\nðŸ’¡ ê¶Œìž¥ ì„¤ì •:")
    print("  - ê°œë°œ/í…ŒìŠ¤íŠ¸: gpt-5-nano (ë¹ ë¥´ê³  ê²½ì œì )")
    print("  - ì¼ë°˜ ì‚¬ìš©: gpt-5-mini (ê· í˜•ìž¡ížŒ ì„±ëŠ¥)")
    print("  - ê³ í’ˆì§ˆ ì½˜í…ì¸ : gpt-5 (ìµœê³  í’ˆì§ˆ)")

    print("\nâš ï¸  ì£¼ì˜ì‚¬í•­:")
    print("  - GPT-5 ì‹œë¦¬ì¦ˆëŠ” temperature íŒŒë¼ë¯¸í„°ê°€ ê³ ì •ë¨ (1.0)")
    print("  - API í‚¤ëŠ” ë°˜ë“œì‹œ ë³´ì•ˆì´ ìœ ì§€ë˜ëŠ” ê³³ì— ì €ìž¥")
    print("  - .env íŒŒì¼ì€ Gitì— ì»¤ë°‹í•˜ì§€ ë§ ê²ƒ")


def validate_env_file(env_path: str = ".env") -> bool:
    """
    .env íŒŒì¼ì˜ ìœ íš¨ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.

    Args:
        env_path: .env íŒŒì¼ ê²½ë¡œ

    Returns:
        bool: ìœ íš¨í•œ ì„¤ì •ì¸ì§€ ì—¬ë¶€
    """
    import os
    from pathlib import Path

    if not Path(env_path).exists():
        print(f"âŒ .env íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {env_path}")
        return False

    # í•„ìˆ˜ ë³€ìˆ˜ ì²´í¬
    required_vars = ["OPENAI_API_KEY", "DEFAULT_LLM_PROVIDER"]
    missing_vars = []

    for var in required_vars:
        if not os.getenv(var):
            missing_vars.append(var)

    if missing_vars:
        print(f"âŒ í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½: {', '.join(missing_vars)}")
        return False

    # ëª¨ë¸ ì„¤ì • í™•ì¸
    model = os.getenv("OPENAI_MODEL", "gpt-5-nano")
    if model not in GPT5_MODELS:
        print(f"âš ï¸  ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸: {model}")
        print(f"   ì§€ì›ë˜ëŠ” ëª¨ë¸: {', '.join(GPT5_MODELS.keys())}")

    print("âœ… í™˜ê²½ ì„¤ì •ì´ ì˜¬ë°”ë¥´ê²Œ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
    return True


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == "validate":
        validate_env_file()
    else:
        print_config_guide()
