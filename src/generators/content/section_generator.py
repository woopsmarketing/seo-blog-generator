# src/generators/content/section_generator.py
# ì„¹ì…˜ ì½˜í…ì¸  ìƒì„±ê¸° - ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ í†µí•œ ì¼ê´€ì„± ìˆëŠ” ì„¹ì…˜ ìƒì„±

import logging
import time
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime
from langchain.schema import HumanMessage, SystemMessage

from src.models.section_models import (
    SectionGenerationOptions,
    SectionGenerationResult,
    SectionContent,
    DocumentMemory,
)
from src.models.blog_models import BlogOutline, BlogSection
from src.generators.content.memory import DocumentMemoryManager, FactTracker
from src.utils.config import load_config
from src.utils.llm_factory import LLMFactory, LLMConfig
from src.utils.rag import SimpleRAG

logger = logging.getLogger(__name__)


class SectionGenerator:
    """
    ì„¹ì…˜ ì½˜í…ì¸  ìƒì„±ê¸°

    ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ í†µí•´ ë¬¸ì„œ ì „ë°˜ì˜ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ë©´ì„œ
    ê° ì„¹ì…˜ë³„ë¡œ 300-500ìì˜ ê³ í’ˆì§ˆ ì½˜í…ì¸ ë¥¼ ìƒì„±
    """

    def __init__(
        self,
        config: Optional[Dict] = None,
        memory_save_path: Optional[str] = None,
        rag: Optional[SimpleRAG] = None,
    ):
        """
        ì„¹ì…˜ ìƒì„±ê¸° ì´ˆê¸°í™”

        Args:
            config: LLM ì„¤ì • (ê¸°ë³¸ê°’: None, ìë™ ë¡œë“œ)
            memory_save_path: ë©”ëª¨ë¦¬ ì €ì¥ ê²½ë¡œ (ì„ íƒì‚¬í•­)
            rag: ì„ íƒì  RAG ì£¼ì… ê°ì²´
        """
        self.config = config or load_config()
        self.llm = None
        self.memory_save_path = memory_save_path
        self.rag = rag

        # LLM ì„¤ì • ë¨¼ì € ìƒì„±
        self.llm_config = LLMConfig(
            provider=self.config["llm"]["default_provider"],
            model=self.config["llm"]["openai_model"],
            temperature=self.config["llm"]["temperature"],
            max_tokens=self.config["llm"]["max_tokens"],
        )

        # ë©”ëª¨ë¦¬ ê´€ë¦¬ ì»´í¬ë„ŒíŠ¸ë“¤ ì´ˆê¸°í™” (LLM ì„¤ì • ì „ë‹¬)
        self.memory_manager = DocumentMemoryManager(self.llm_config)
        self.fact_tracker = FactTracker(self.config)

        self.logger = logger
        self._initialize_llm()

    def _initialize_llm(self) -> None:
        """ì½˜í…ì¸  ìƒì„±ì„ ìœ„í•œ LLM ì´ˆê¸°í™”"""
        try:
            factory = LLMFactory()
            self.llm = factory.create_llm(self.llm_config)
            self.logger.info(
                f"ì„¹ì…˜ ìƒì„±ê¸° LLM ì´ˆê¸°í™” ì™„ë£Œ: {self.llm_config.provider}/{self.llm_config.model}"
            )

        except Exception as e:
            self.logger.error(f"LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def initialize_document(
        self,
        title: str,
        keyword: str,
        outline: BlogOutline,
        target_audience: str = "general",
    ) -> DocumentMemory:
        """
        ìƒˆ ë¬¸ì„œì— ëŒ€í•œ ë©”ëª¨ë¦¬ ì´ˆê¸°í™”

        Args:
            title: ë¬¸ì„œ ì œëª©
            keyword: íƒ€ê²Ÿ í‚¤ì›Œë“œ
            outline: ë¸”ë¡œê·¸ ì•„ì›ƒë¼ì¸
            target_audience: íƒ€ê²Ÿ ë…ì

        Returns:
            ì´ˆê¸°í™”ëœ DocumentMemory ê°ì²´
        """
        self.logger.info(f"ë¬¸ì„œ ì´ˆê¸°í™”: '{title}' (í‚¤ì›Œë“œ: '{keyword}')")

        memory = self.memory_manager.initialize_memory(
            title=title,
            keyword=keyword,
            outline=outline,
            target_audience=target_audience,
        )

        self.logger.info(f"ë¬¸ì„œ ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ: {len(outline.sections)}ê°œ ì„¹ì…˜")
        return memory

    def generate_section_content(
        self,
        section: BlogSection,
        section_index: int,
        context: Dict[str, Any],
        options: SectionGenerationOptions = None,
    ) -> SectionGenerationResult:
        """íŠ¹ì • ì„¹ì…˜ì˜ ì½˜í…ì¸  ìƒì„±"""

        if options is None:
            options = SectionGenerationOptions()

        section_id = str(section_index)
        section_title = section.h2
        subsection_titles = section.h3

        self.logger.info(f"ì„¹ì…˜ ìƒì„± ì‹œì‘: {section_index} - {section_title}")

        try:
            start_time = time.time()

            # ë©”ëª¨ë¦¬ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° + í‚¤ì›Œë“œ ì „ëµ ì¶”ê°€
            memory_context = self.memory_manager.get_context_for_section(
                section_id, section_title
            )

            # í‚¤ì›Œë“œ ì „ëµì„ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
            if "keyword_strategy" in context:
                memory_context["keyword_strategy"] = context["keyword_strategy"]

            # ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸ì™€ ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ ë³‘í•©
            combined_context = {**context, **memory_context}

            # ì½˜í…ì¸  ìƒì„± í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_section_generation_prompt(
                section, section_index, combined_context
            )

            # RAG ì£¼ì…: ragê°€ ìˆë‹¤ë©´ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì•ë‹¨ì— ì¶”ê°€
            if self.rag:
                rag_query = f"{combined_context.get('document_title','')} - {section_title} í•µì‹¬ ë‚´ìš© ìš”ì•½"
                rag_context = self.rag.query(rag_query)
                if rag_context:
                    prompt = f"{rag_context}\n\n---\n\n{prompt}"

            # LLMìœ¼ë¡œ ì½˜í…ì¸  ìƒì„±
            message = HumanMessage(content=prompt)
            response = self.llm.invoke([message])
            section_content = response.content.strip()

            # SectionContent ê°ì²´ ìƒì„±
            section_content_obj = SectionContent(
                section_id=section_id,
                title=section_title,
                content=section_content,
                word_count=len(section_content),
                key_points=[],  # ê°„ë‹¨íˆ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì„¤ì •
                mentioned_facts=[],  # ê°„ë‹¨íˆ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì„¤ì •
            )

            # ë©”ëª¨ë¦¬ì— ìƒì„±ëœ ì„¹ì…˜ ì¶”ê°€
            self.memory_manager.add_generated_section(section_content_obj)

            # ì‚¬ì‹¤ ë° ìš©ì–´ ì¶”ì¶œ
            extracted_facts = []
            new_terminology = {}

            if self.fact_tracker:
                extracted_facts = self.fact_tracker.extract_facts_from_content(
                    section_content_obj, combined_context["target_keyword"]
                )
                new_terminology = self.fact_tracker.extract_terminology_from_content(
                    section_content_obj, combined_context["target_keyword"]
                )

                # ë©”ëª¨ë¦¬ì— ì¶”ê°€
                if extracted_facts:
                    self.memory_manager.add_facts(extracted_facts)
                if new_terminology:
                    self.memory_manager.add_terminology(new_terminology)

            generation_time = time.time() - start_time

            # ê²°ê³¼ ê°ì²´ ìƒì„±
            result = SectionGenerationResult(
                section_content=section_content_obj,
                extracted_facts=extracted_facts,
                new_terminology=new_terminology,
                generation_time=generation_time,
                token_usage={},  # ì‹¤ì œ í† í° ì‚¬ìš©ëŸ‰ì€ LLM ì‘ë‹µì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ
                success=True,
            )

            self.logger.info(
                f"ì„¹ì…˜ ìƒì„± ì™„ë£Œ: {section_index} ({len(section_content)}ì, {generation_time:.1f}ì´ˆ)"
            )
            return result

        except Exception as e:
            self.logger.error(f"ì„¹ì…˜ ìƒì„± ì‹¤íŒ¨: {section_index} - {e}")

            # ë¹ˆ SectionContent ê°ì²´ ìƒì„±
            empty_section_content = SectionContent(
                section_id=section_id,
                title=section_title,
                content="",
                word_count=0,
                key_points=[],
                mentioned_facts=[],
            )

            return SectionGenerationResult(
                section_content=empty_section_content,
                extracted_facts=[],
                new_terminology={},
                generation_time=0,
                token_usage={},
                success=False,
                error_message=str(e),
            )

    def generate_full_document_content(
        self, outline: BlogOutline, options: Optional[SectionGenerationOptions] = None
    ) -> List[SectionGenerationResult]:
        """
        ì „ì²´ ë¬¸ì„œì˜ ëª¨ë“  ì„¹ì…˜ ì½˜í…ì¸ ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ìƒì„±

        Args:
            outline: ë¸”ë¡œê·¸ ì•„ì›ƒë¼ì¸
            options: ìƒì„± ì˜µì…˜

        Returns:
            ëª¨ë“  ì„¹ì…˜ì˜ ìƒì„± ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        self.logger.info(f"ì „ì²´ ë¬¸ì„œ ìƒì„± ì‹œì‘: {len(outline.sections)}ê°œ ì„¹ì…˜")

        results = []

        for i, section in enumerate(outline.sections, 1):
            section_id = str(i)

            # í•˜ìœ„ ì„¹ì…˜ ì œëª©ë“¤ ì¤€ë¹„
            subsection_titles = section.h3 if section.h3 else []

            # ì„¹ì…˜ ì½˜í…ì¸  ìƒì„±
            result = self.generate_section_content(
                section=section,
                section_index=i,
                context={
                    "document_title": outline.title,
                    "target_keyword": outline.meta.target_keyword,
                    "target_audience": "general",
                },
                options=options,
            )

            results.append(result)

            # ì„±ê³µí•œ ê²½ìš°ì—ë§Œ ì§„í–‰ (ì‹¤íŒ¨ ì‹œ ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì†)
            if result.success:
                self.logger.info(f"ì„¹ì…˜ {section_id} ìƒì„± ì™„ë£Œ")
            else:
                self.logger.warning(f"ì„¹ì…˜ {section_id} ìƒì„± ì‹¤íŒ¨, ê³„ì† ì§„í–‰")

        # ì „ì²´ í†µê³„ ë¡œê¹…
        successful_sections = sum(1 for r in results if r.success)
        total_words = sum(r.section_content.word_count for r in results if r.success)
        total_time = sum(r.generation_time for r in results)

        self.logger.info(
            f"ì „ì²´ ë¬¸ì„œ ìƒì„± ì™„ë£Œ: {successful_sections}/{len(results)} ì„¹ì…˜ ì„±ê³µ, "
            f"ì´ {total_words:,}ì, {total_time:.2f}ì´ˆ"
        )

        return results

    def get_memory_stats(self) -> Dict[str, any]:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ìƒíƒœ í†µê³„ ë°˜í™˜"""
        return self.memory_manager.get_memory_stats()

    def _create_section_generation_prompt(
        self,
        section: BlogSection,
        section_index: int,
        context: Dict[str, Any],
    ) -> str:
        """ì„¹ì…˜ë³„ ë§ì¶¤í˜• í”„ë¡¬í”„íŠ¸ ìƒì„± - ë‹¤ìŒ ì„¹ì…˜ ì—°ê²° í¬í•¨"""

        # ë‹¤ìŒ ì„¹ì…˜ ì •ë³´ í™•ì¸
        all_sections = context.get("all_sections", [])
        next_section = (
            all_sections[section_index] if section_index < len(all_sections) else None
        )

        # ì„¹ì…˜ íƒ€ì…ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
        return self._create_section_specific_prompt(
            section, section_index, context, next_section
        )

    def _create_section_specific_prompt(
        self,
        section: BlogSection,
        section_index: int,
        context: Dict[str, Any],
        next_section: BlogSection = None,
    ) -> str:
        """ì„¹ì…˜ íƒ€ì…ë³„ ì„¸ë¶€ í”„ë¡¬í”„íŠ¸ ìƒì„± - GPT-5-nano ìµœì í™” ë° ìì—°ìŠ¤ëŸ¬ìš´ ì½˜í…ì¸  í”Œë¡œìš°"""

        # í‚¤ì›Œë“œ ì „ëµ ì •ë³´ ì¶”ì¶œ
        keyword_strategy = context.get("keyword_strategy")

        # ì „ì²´ ì„¹ì…˜ ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ìµœì  ê¸¸ì´ ê³„ì‚°
        total_sections = len(context.get("all_sections", []))
        total_target_length = 4500  # 4000-6000 ë²”ìœ„ì˜ ì¤‘ê°„ê°’

        # ì„¹ì…˜ë³„ ê¶Œì¥ ê¸¸ì´ ê³„ì‚° (ì²« ì„¹ì…˜ì€ ì§§ê²Œ, ë‚˜ë¨¸ì§€ëŠ” ê· ë“± ë¶„ë°°)
        if section_index == 1:  # ê°œìš” ì„¹ì…˜
            target_length = "400-500ì"
            per_section_target = 400
        elif (
            section_index == total_sections and "FAQ" in section.h2.upper()
        ):  # ë§ˆì§€ë§‰ FAQ ì„¹ì…˜
            target_length = "300-400ì"
            per_section_target = 350
        else:  # ì¼ë°˜ ì„¹ì…˜ë“¤
            remaining_length = (
                total_target_length - 400 - (350 if total_sections > 2 else 0)
            )
            remaining_sections = max(
                1, total_sections - (2 if total_sections > 2 else 1)
            )
            per_section_target = remaining_length // remaining_sections
            target_length = f"{per_section_target-50}-{per_section_target+100}ì"

        is_overview_section = section_index == 1

        # í‚¤ì›Œë“œ ì „ëµ ì •ë³´ êµ¬ì„±
        keyword_info = ""
        if keyword_strategy:
            primary_keyword = keyword_strategy.primary_keyword
            target_frequency = keyword_strategy.target_frequency

            # LSI í‚¤ì›Œë“œ ì •ë³´
            lsi_keywords = [lsi.keyword for lsi in keyword_strategy.lsi_keywords[:6]]
            lsi_keywords_str = ", ".join(lsi_keywords) if lsi_keywords else "ì—†ìŒ"

            # ë¡±í…Œì¼ í‚¤ì›Œë“œ ì •ë³´
            longtail_keywords = [
                lt.phrase for lt in keyword_strategy.longtail_keywords[:3]
            ]
            longtail_keywords_str = (
                ", ".join(longtail_keywords) if longtail_keywords else "ì—†ìŒ"
            )

            # ì˜ë¯¸ì  ë³€í˜• ì •ë³´
            variations = keyword_strategy.semantic_variations[:4]
            variations_str = ", ".join(variations) if variations else "ì—†ìŒ"

            keyword_info = f"""
**í‚¤ì›Œë“œ ì „ëµ (ë§¤ìš° ì¤‘ìš”):**
- í•µì‹¬ í‚¤ì›Œë“œ '{primary_keyword}': ì´ ì„¹ì…˜ì—ì„œ ìµœëŒ€ 1-2íšŒë§Œ ì‚¬ìš© (ì „ì²´ ë¬¸ì„œì—ì„œ ì´ {target_frequency}íšŒ ëª©í‘œ)
- LSI í‚¤ì›Œë“œ í™œìš©: {lsi_keywords_str}
- ë¡±í…Œì¼ í‚¤ì›Œë“œ ì°¸ê³ : {longtail_keywords_str}  
- ì˜ë¯¸ì  ë³€í˜• í‘œí˜„: {variations_str}

**í‚¤ì›Œë“œ ì‚¬ìš© ì›ì¹™:**
1. í•µì‹¬ í‚¤ì›Œë“œë¥¼ ê³¼ë„í•˜ê²Œ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš” (ìì—°ìŠ¤ëŸ¬ì›€ ìš°ì„ )
2. LSI í‚¤ì›Œë“œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë³¸ë¬¸ì— í¬í•¨í•˜ì„¸ìš”
3. ì˜ë¯¸ì  ë³€í˜• í‘œí˜„ì„ í™œìš©í•˜ì—¬ ë‹¤ì–‘ì„±ì„ ë†’ì´ì„¸ìš”
4. í‚¤ì›Œë“œ ë°€ë„ë³´ë‹¤ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë‚´ìš© íë¦„ì„ ìš°ì„ í•˜ì„¸ìš”
"""
        else:
            keyword_info = f"""
**í‚¤ì›Œë“œ ì‚¬ìš©:**
- íƒ€ê²Ÿ í‚¤ì›Œë“œ '{context['target_keyword']}': ì´ ì„¹ì…˜ì—ì„œ 1-2íšŒ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
"""

        # ì´ì „ ì„¹ì…˜ ì»¨í…ìŠ¤íŠ¸ (LangChain ë©”ëª¨ë¦¬ í™œìš©)
        previous_context = ""
        if section_index > 1:
            previous_context = self.memory_manager.get_natural_flow_context(section.h2)
            if previous_context:
                previous_context = f"""
**ì´ì „ ë‚´ìš©ê³¼ì˜ ì—°ê²°:**
{previous_context}

ì´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì°¸ê³ í•˜ì—¬ ë§¤ë„ëŸ½ê²Œ ì´ì–´ê°€ë˜, ëª…ì‹œì ì¸ ì—°ê²° ë¬¸êµ¬("ì´ì „ ì„¹ì…˜ì—ì„œ", "ì•ì—ì„œ ì–¸ê¸‰í•œ")ëŠ” í”¼í•˜ì„¸ìš”.
"""

        # ë‹¤ìŒ ì„¹ì…˜ ì—°ê²° ì •ë³´ ìƒì„± (ê°œì„ ëœ í”Œë¡œìš°)
        next_section_hint = ""
        if next_section and section_index < len(context.get("all_sections", [])):
            # ë§ˆì§€ë§‰ ì„¹ì…˜ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ë‹¤ìŒ ì„¹ì…˜ íŒíŠ¸ ì¶”ê°€
            next_section_hint = f"""
**ğŸ”„ ë‹¤ìŒ ì„¹ì…˜ ì—°ê²° ê°€ì´ë“œ (ë§¤ìš° ì¤‘ìš”):**
ë‹¤ìŒì— '{next_section.h2}' ì„¹ì…˜ì´ ì´ì–´ì§‘ë‹ˆë‹¤. 
ì´ ì„¹ì…˜ì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ì— ë‹¤ìŒ ì„¹ì…˜ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ëŠ” í•œ ë¬¸ì¥ì„ í¬í•¨í•˜ì„¸ìš”.

ì˜ˆì‹œ ì—°ê²° ë¬¸êµ¬:
- "ì´ì œ {next_section.h2.lower()}ì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
- "ë‹¤ìŒìœ¼ë¡œëŠ” {next_section.h2.lower()}ì— ëŒ€í•´ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤."
- "ê·¸ë ‡ë‹¤ë©´ {next_section.h2.lower()}ì€ ì–´ë–»ê²Œ í•´ì•¼ í• ê¹Œìš”?"

**ì¤‘ìš”**: ì—°ê²° ë¬¸êµ¬ëŠ” ì„¹ì…˜ì˜ ë§ˆì§€ë§‰ ë¬¸ë‹¨ì— ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨ë˜ì–´ì•¼ í•˜ë©°, ì–µì§€ìŠ¤ëŸ½ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤.
"""
        else:
            # ë§ˆì§€ë§‰ ì„¹ì…˜ì¸ ê²½ìš°
            next_section_hint = """
**âœ… ë§ˆì§€ë§‰ ì„¹ì…˜ ë§ˆë¬´ë¦¬:**
ì´ ì„¹ì…˜ì´ ë§ˆì§€ë§‰ì´ë¯€ë¡œ, ì „ì²´ ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë§ˆë¬´ë¦¬í•˜ë˜ ê²°ë¡ í˜• í‘œí˜„ì€ í”¼í•˜ê³  ë…ìì—ê²Œ ë„ì›€ì´ ë˜ëŠ” ë‚´ìš©ìœ¼ë¡œ ëë‚´ì„¸ìš”.
"""

        prompt = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ë¸”ë¡œê·¸ ì½˜í…ì¸  ì‘ì„±ìì…ë‹ˆë‹¤. 
ë‹¤ìŒ ì„¹ì…˜ì˜ ê³ í’ˆì§ˆ ì½˜í…ì¸ ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

**ì„¹ì…˜ ì •ë³´:**
- ì„¹ì…˜ ì œëª©: {section.h2}
- ëª©í‘œ ê¸¸ì´: {target_length}
- í•˜ìœ„ ì„¹ì…˜: {section.h3 if section.h3 else 'ì—†ìŒ'}
- ë¬¸ì„œ ì œëª©: {context['document_title']}
- íƒ€ê²Ÿ í‚¤ì›Œë“œ: {context['target_keyword']}

{keyword_info}

{previous_context}

{next_section_hint}

**ğŸš¨ ì¤‘ìš” - ì¶œë ¥ í˜•ì‹:**
- ì ˆëŒ€ë¡œ "ì„¹ì…˜:", "ì œëª©:", "ë‚´ìš©:" ê°™ì€ ë©”íƒ€ ì •ë³´ë¥¼ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”
- ì„¹ì…˜ ì œëª© {section.h2}ì„ ë‹¤ì‹œ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš” (ë³„ë„ ì²˜ë¦¬ë¨)
- ë°”ë¡œ ë³¸ë¬¸ ë‚´ìš©ë¶€í„° ì‹œì‘í•˜ì„¸ìš”
- H3 í•˜ìœ„ ì„¹ì…˜ì´ ìˆëŠ” ê²½ìš°: ### í•˜ìœ„ì„¹ì…˜ì œëª© í˜•íƒœë¡œ ì‘ì„±

**ì‘ì„± ê°€ì´ë“œë¼ì¸:**
1. ëª©í‘œ ê¸¸ì´ {target_length}ë¥¼ ì •í™•íˆ ì¤€ìˆ˜
2. í‚¤ì›Œë“œ '{context['target_keyword']}'ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨ (ê³¼ë„í•œ ë°˜ë³µ ê¸ˆì§€)
3. {'ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ì†Œê°œë¡œ ë…ì ê´€ì‹¬ ìœ ë„' if is_overview_section else 'êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ ì œê³µ'}
4. ë…ìê°€ ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì‹¤ì§ˆì  ë‚´ìš© ì¤‘ì‹¬
5. ì „ë¬¸ ìš©ì–´ ì‚¬ìš© ì‹œ ê°„ë‹¨í•œ ì„¤ëª… í¬í•¨

**ì ˆëŒ€ ê¸ˆì§€ ì‚¬í•­:**
- ì„¹ì…˜ ë©”íƒ€ì •ë³´ ì¶œë ¥: "ì„¹ì…˜: XXX", "ì œëª©: XXX", "ë‚´ìš©: XXX"
- ì„¹ì…˜ ì œëª© ì¬ì¶œë ¥: "{section.h2}" ë‹¤ì‹œ ì“°ì§€ ë§ˆì„¸ìš”
- ê²°ë¡ í˜• í‘œí˜„: "ë§ˆì§€ë§‰ìœ¼ë¡œ", "ê²°ë¡ ì ìœ¼ë¡œ", "ì •ë¦¬í•˜ìë©´", "ìš”ì•½í•˜ë©´"
- ëª…ì‹œì  ì°¸ì¡°: "ì•ì—ì„œ ë§í•œ", "ì´ì „ ì„¹ì…˜ì—ì„œ", "ìœ„ì—ì„œ ì–¸ê¸‰í•œ"

**ì„¹ì…˜ë³„ íŠ¹í™” ì§€ì¹¨:**
{'ê°œìš” ì„¹ì…˜: í•µì‹¬ ê°œë… ê°„ë‹¨ ì†Œê°œ, ë…ì í˜¸ê¸°ì‹¬ ìê·¹' if is_overview_section else ('FAQ ì„¹ì…˜: Q: ì§ˆë¬¸, A: ë‹µë³€ í˜•ì‹, ê° Q&AëŠ” 2-3ë¬¸ì¥' if 'FAQ' in section.h2.upper() else 'ë³¸ë¬¸ ì„¹ì…˜: ìƒì„¸ ì •ë³´, êµ¬ì²´ì  ì˜ˆì‹œ, ë‹¨ê³„ë³„ ì„¤ëª…')}

**ì—°ê²°ì„±:**
- ì´ì „ ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ë°›ë˜ ëª…ì‹œì  ì°¸ì¡°ëŠ” í”¼í•˜ì„¸ìš”
- {'ë§ˆì§€ë§‰ ë¬¸ë‹¨ì— ë‹¤ìŒ ì„¹ì…˜ ì—°ê²° ë¬¸êµ¬ í¬í•¨' if next_section else 'ìì—°ìŠ¤ëŸ½ê²Œ ë§ˆë¬´ë¦¬'}

**ì¶œë ¥ ì˜ˆì‹œ:**
```
### í•˜ìœ„ì„¹ì…˜ì œëª© (ìˆëŠ” ê²½ìš°ë§Œ)
ë³¸ë¬¸ ë‚´ìš©ì´ ë°”ë¡œ ì‹œì‘ë©ë‹ˆë‹¤. ì„¹ì…˜ ì œëª©ì´ë‚˜ ë©”íƒ€ ì •ë³´ëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

ê° ë¬¸ë‹¨ì€ 3-5ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±í•˜ë©°, ë…ìì—ê²Œ ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

{'ë‹¤ìŒìœ¼ë¡œëŠ” ' + next_section.h2.lower() + 'ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.' if next_section else ''}
```

**í•µì‹¬: ë°”ë¡œ ë³¸ë¬¸ ë‚´ìš©ë¶€í„° ì¶œë ¥í•˜ê³ , ì–´ë–¤ ë©”íƒ€ ì •ë³´ë„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”!**
"""
        return prompt

    def _generate_content_with_llm(self, prompt: str) -> str:
        """LLMì„ í†µí•œ ì‹¤ì œ ì½˜í…ì¸  ìƒì„±"""
        if not self.llm:
            raise ValueError("LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        try:
            messages = [
                SystemMessage(
                    content="ë‹¹ì‹ ì€ ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ ë¸”ë¡œê·¸ ì½˜í…ì¸ ë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
                ),
                HumanMessage(content=prompt),
            ]

            response = self.llm.invoke(messages)
            content = response.content.strip()

            # ê¸°ë³¸ì ì¸ ì½˜í…ì¸  ê²€ì¦
            if len(content) < 100:
                raise ValueError("ìƒì„±ëœ ì½˜í…ì¸ ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")

            return content

        except Exception as e:
            self.logger.error(f"LLM ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {e}")
            raise

    def _extract_key_points_from_content(self, content: str) -> List[str]:
        """ì½˜í…ì¸ ì—ì„œ í•µì‹¬ í¬ì¸íŠ¸ë“¤ì„ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ í¬ì¸íŠ¸ ì¶”ì¶œ ë¡œì§
        # í–¥í›„ ë” ì •êµí•œ NLP ê¸°ë²•ìœ¼ë¡œ ê°œì„  ê°€ëŠ¥

        key_points = []

        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        sentences = [s.strip() for s in content.split(".") if len(s.strip()) > 10]

        # ì¤‘ìš”í•´ ë³´ì´ëŠ” ë¬¸ì¥ë“¤ ì¶”ì¶œ (í‚¤ì›Œë“œ ê¸°ë°˜)
        important_keywords = [
            "ì¤‘ìš”í•œ",
            "í•µì‹¬",
            "í•„ìˆ˜",
            "ë°˜ë“œì‹œ",
            "ì£¼ëª©í• ",
            "ê¸°ì–µí• ",
            "í¬ì¸íŠ¸",
            "ë°©ë²•",
            "ì „ëµ",
            "ê¸°ë²•",
            "ë…¸í•˜ìš°",
            "íŒ",
            "ë¹„ê²°",
        ]

        for sentence in sentences[:10]:  # ìµœëŒ€ 10ê°œ ë¬¸ì¥ë§Œ ê²€í† 
            if any(keyword in sentence for keyword in important_keywords):
                if len(sentence) < 100:  # ë„ˆë¬´ ê¸´ ë¬¸ì¥ì€ ì œì™¸
                    key_points.append(sentence.strip())

        # ìµœëŒ€ 5ê°œì˜ í•µì‹¬ í¬ì¸íŠ¸ë§Œ ë°˜í™˜
        return key_points[:5]
